{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd #data processing\n",
    "\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5) (14897, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fake_test = pd.read_csv('../fake-news/Fake.csv')\n",
    "real_test = pd.read_csv('../fake-news/True.csv')\n",
    "fake_label = [0 for i in range(fake_test.shape[0])]\n",
    "real_label = [1 for i in range(real_test.shape[0])]\n",
    "fake_test = fake_test.assign(label = fake_label)\n",
    "real_test = real_test.assign(label = real_label)\n",
    "\n",
    "x1 = pd.concat([fake_test,real_test])\n",
    "\n",
    "x1 = x1.sample(frac=1)\n",
    "\n",
    "\n",
    "\n",
    "train , test =  x1[:30000], x1[30001:]\n",
    "\n",
    "print(train.shape,test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>Top U.S. diplomat for Middle East to retire, U...</td>\n",
       "      <td>WASHINGTON (Reuters) - The top U.S. diplomat f...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 16, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>Tillerson avoids public conflict with Trump ov...</td>\n",
       "      <td>WASHINGTON (Reuters) - While he has swallowed ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 17, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>Donald Trump Just Posted The Weirdest Ad You’...</td>\n",
       "      <td>Everyone knows that Republican front runner Do...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14175</th>\n",
       "      <td>Indian navy the odd man out in Asia's 'Quad' a...</td>\n",
       "      <td>NEW DELHI (Reuters) - The Trump administration...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>WATCH: Trump Brags About Himself And Trump To...</td>\n",
       "      <td>It took all of a few seconds for Donald Trump ...</td>\n",
       "      <td>News</td>\n",
       "      <td>September 18, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "3763   Top U.S. diplomat for Middle East to retire, U...   \n",
       "4885   Tillerson avoids public conflict with Trump ov...   \n",
       "7464    Donald Trump Just Posted The Weirdest Ad You’...   \n",
       "14175  Indian navy the odd man out in Asia's 'Quad' a...   \n",
       "358     WATCH: Trump Brags About Himself And Trump To...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "3763   WASHINGTON (Reuters) - The top U.S. diplomat f...  politicsNews   \n",
       "4885   WASHINGTON (Reuters) - While he has swallowed ...  politicsNews   \n",
       "7464   Everyone knows that Republican front runner Do...          News   \n",
       "14175  NEW DELHI (Reuters) - The Trump administration...     worldnews   \n",
       "358    It took all of a few seconds for Donald Trump ...          News   \n",
       "\n",
       "                     date  label  \n",
       "3763        May 16, 2017       1  \n",
       "4885      March 17, 2017       1  \n",
       "7464       March 16, 2016      0  \n",
       "14175  November 22, 2017       1  \n",
       "358    September 18, 2017      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5) (14897, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n",
      "************\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n",
    "print('************')\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.fillna(' ')\n",
    "train=train.fillna(' ')\n",
    "test['total']= test['title']+' ' + test['text']\n",
    "train['total']=train['title']+' '+train['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Wordcloud Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuations from the String  \n",
    "s = \"!</> hello please$$ </>^s!!!u%%bs&&%$cri@@@be^^^&&!& </>*to@# the&&\\ cha@@@n##%^^&nel!@# %%$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = re.sub(r'[^\\w\\s]','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if any substring doesn't hold words or space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hello please subscribe to the channel \n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-30ac1b2e5fce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8df2310c77c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'helo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words.append('helo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Covid-19 pandemic has impacted many countries and what it did to economy is very stressful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-6bd2c8f40453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(sentence)\n",
    "words = [w for w in words if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-730c51b3e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ea993abd09e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlemmatizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"been had done languages cities mice\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "input_str=\"been had done languages cities mice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c703216f732b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Tokenize the sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Lemmatize each word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "#Tokenize the sentence\n",
    "input_str=nltk.word_tokenize(input_str)\n",
    "\n",
    "#Lemmatize each word\n",
    "for word in input_str:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer=WordNetLemmatizer()\n",
    "#for index,row in train.iterrows():\n",
    "    #filter_sentence = ''\n",
    "    \n",
    "    #sentence = row['total']\n",
    "    #sentence = re.sub(r'[^\\w\\s]','',sentence) #cleaning\n",
    "    \n",
    "    #words = nltk.word_tokenize(sentence) #tokenization\n",
    "    \n",
    "    #words = [w for w in words if not w in stop_words]  #stopwords removal\n",
    "    \n",
    "    #for word in words:\n",
    "        #filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(word)).lower()\n",
    "        \n",
    "    #train.loc[index,'total'] = filter_sentence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying NLP Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['total']\n",
    "Y_train = train['label']\n",
    "Y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words / CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-iDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(features, max_features):\n",
    "    vectorizer = TfidfVectorizer( stop_words='english',\n",
    "                            decode_error='strict',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1, 2),\n",
    "                            max_features=max_features\n",
    "                            #max_df=0.5 # Verwendet im ML-Kurs unter Preprocessing                   \n",
    "                            )\n",
    "    feature_vec = vectorizer.fit_transform(features)\n",
    "    return feature_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = vectorize_text(['hello how are you doing','hi i am doing fine'],30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'hello how  doing','hi  doing fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44943642, 0.        , 0.        , 0.6316672 , 0.6316672 ,\n",
       "        0.        , 0.        ],\n",
       "       [0.33517574, 0.47107781, 0.47107781, 0.        , 0.        ,\n",
       "        0.47107781, 0.47107781]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature extraction using count vectorization and tfidf.\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(X_train)\n",
    "freq_term_matrix = count_vectorizer.transform(X_train)\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in iter.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counts = count_vectorizer.transform(test['total'].values)\n",
    "test_tfidf = tfidf.transform(test_counts)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e7, max_iter = 1000)\n",
    "logreg.fit(tf_idf_matrix, Y_train)\n",
    "pred = logreg.predict(test_tfidf)\n",
    "print('Accuracy of Logistic classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(tf_idf_matrix, Y_train)))\n",
    "print('Accuracy of Logistic classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(test_tfidf, Y_test)))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logreg.predict(test_tfidf)\n",
    "print('Accuracy of Logistic classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(tf_idf_matrix, Y_train)))\n",
    "print('Accuracy of Logistic classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(test_tfidf, Y_test)))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(tf_idf_matrix, Y_train)\n",
    "pred = NB.predict(test_tfidf)\n",
    "print('Accuracy of NB  classifier on training set: {:.2f}'\n",
    "     .format(NB.score(tf_idf_matrix, Y_train)))\n",
    "print('Accuracy of NB classifier on test set: {:.2f}'\n",
    "     .format(NB.score(test_tfidf, Y_test)))\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.75)\n",
    "vec_train=tfidf_vectorizer.fit_transform(X_train.values.astype('U')) \n",
    "vec_test=tfidf_vectorizer.transform(test['total'].values.astype('U'))\n",
    "\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(vec_train,Y_train)\n",
    "y_pred=pac.predict(vec_test)\n",
    "score=accuracy_score(Y_test,y_pred)\n",
    "print(f'PAC Accuracy: {round(score*100,2)}%')\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 98.83%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake_test = pd.read_csv('../fake-news/Fake.csv')\n",
    "real_test = pd.read_csv('../fake-news/True.csv')\n",
    "fake_label = [0 for i in range(fake_test.shape[0])]\n",
    "real_label = [1 for i in range(real_test.shape[0])]\n",
    "fake_test = fake_test.assign(label = fake_label)\n",
    "real_test = real_test.assign(label = real_label)\n",
    "\n",
    "x1 = pd.concat([fake_test,real_test])\n",
    "x1['total'] = x1['title'] + \" \" + x1['text']\n",
    "\n",
    "X=tfidf_vectorizer.transform(x1['total'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, x1['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 99.21%\n"
     ]
    }
   ],
   "source": [
    "X = count_vectorizer.transform(x1['total'].values)\n",
    "scores = cross_val_score(logreg, X, x1['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 92.57%\n"
     ]
    }
   ],
   "source": [
    "X = count_vectorizer.transform(x1['total'].values)\n",
    "scores = cross_val_score(NB, X, x1['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      30000\n",
       "text       30000\n",
       "subject    30000\n",
       "date       30000\n",
       "label      30000\n",
       "total      30000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 96.7%\n",
      "K Fold Accuracy: 96.61%\n",
      "K Fold Accuracy: 90.84%\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../fake-news/train.csv')\n",
    "train = train.dropna()\n",
    "test = pd.read_csv('../fake-news/test.csv')\n",
    "train['total'] = train['title'] + \" \" + train['text']\n",
    "\n",
    "X=tfidf_vectorizer.transform(train['total'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, train['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')\n",
    "\n",
    "X = count_vectorizer.transform(train['total'].values)\n",
    "scores = cross_val_score(logreg, X, train['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')\n",
    "\n",
    "X = count_vectorizer.transform(train['total'].values)\n",
    "scores = cross_val_score(NB, X, train['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X= count_vectorizer.transform([\"They hope to raise money to elect dozens of Democrats ahead of next week’s presidential and congressional elections. Cher announced on Twitter: “THURSDAY. Join me and [Hillary Clinton] to SIP TEA AND ELECT DEMOCRATS” Breitbart reports: Tickets for the event start at just $10 and go all the way up to $5,000 for a premium ticket that includes a “pre-event reception with Hillary & Cher.” “Chip in $10 or more to join our virtual conversation with Hillary Clinton & Cher on Thursday, October 29 at 4:30 PM ET,” the event’s description read. “Don’t miss this un-BELIEVE-able opportunity to hear from these two icons! Anything you donate will help elect over 50 House candidates and other Democrats on Election Day.” The event comes just days before next week’s presidential election in which both women are desperately fighting for a victory for Joe Biden over Donald Trump.As part of her 73rd birthday celebrations on Monday, Clinton pleaded with supporters to make a final push to remove Trump from office, four years after her devastating defeat in the 2016 presidential election.\"])\n",
    "X1 = count_vectorizer.transform([\"it’s the second-high nmber of daiy confirmed infecons since the beginning of the pandemic, behind the 3,004 reported on Sunday. The new cases account for just over three per cent of the 92,328 tests completed over the past day, according to provincial health data. Canada has now seen a total of 228,301 confirmed cases of COVID-19 to date, of which 191,208 have recovered from the disease. Over 11.5 million tests have been completed. Forty-two new deaths were also reported Thursday, bringing the national death toll to 10,074. Over a third of those deaths were historical and did not occur over the past 24 hours.\"])\n",
    "#y_pred=pac.predict(X1)\n",
    "#print(y_pred)\n",
    "pred2 = logreg.predict(X1)\n",
    "print(pred1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
