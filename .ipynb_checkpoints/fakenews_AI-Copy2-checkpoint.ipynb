{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd #data processing\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5) (14897, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fake_test = pd.read_csv('../fake-news/Fake.csv')\n",
    "real_test = pd.read_csv('../fake-news/True.csv')\n",
    "fake_label = [0 for i in range(fake_test.shape[0])]\n",
    "real_label = [1 for i in range(real_test.shape[0])]\n",
    "fake_test = fake_test.assign(label = fake_label)\n",
    "real_test = real_test.assign(label = real_label)\n",
    "\n",
    "x1 = pd.concat([fake_test,real_test])\n",
    "\n",
    "x1 = x1.sample(frac=1)\n",
    "\n",
    "\n",
    "\n",
    "train , test =  x1[:30000], x1[30001:]\n",
    "\n",
    "print(train.shape,test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19355</th>\n",
       "      <td>JULIAN ASSANGE REVEALS John Podesta’s Hilariou...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jan 4, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>White House looks past conservatives on tax re...</td>\n",
       "      <td>WASHINGTON (Reuters) - Fresh off a defeat on U...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 26, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>New York girds itself for Trump's first visit ...</td>\n",
       "      <td>NEW YORK (Reuters) - New York is bracing for P...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 2, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>Trump to name Republican donor Kelly Craft as ...</td>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 14, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>Tunisian migrant, navy boats collide; eight bo...</td>\n",
       "      <td>TUNIS/ROME (Reuters) - At least eight people d...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 9, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "19355  JULIAN ASSANGE REVEALS John Podesta’s Hilariou...   \n",
       "4672   White House looks past conservatives on tax re...   \n",
       "3962   New York girds itself for Trump's first visit ...   \n",
       "3193   Trump to name Republican donor Kelly Craft as ...   \n",
       "17996  Tunisian migrant, navy boats collide; eight bo...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "19355                                                        left-news   \n",
       "4672   WASHINGTON (Reuters) - Fresh off a defeat on U...  politicsNews   \n",
       "3962   NEW YORK (Reuters) - New York is bracing for P...  politicsNews   \n",
       "3193   WASHINGTON (Reuters) - President Donald Trump ...  politicsNews   \n",
       "17996  TUNIS/ROME (Reuters) - At least eight people d...     worldnews   \n",
       "\n",
       "                   date  label  \n",
       "19355       Jan 4, 2017      0  \n",
       "4672    March 26, 2017       1  \n",
       "3962       May 2, 2017       1  \n",
       "3193     June 14, 2017       1  \n",
       "17996  October 9, 2017       1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5) (14897, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n",
      "************\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n",
    "print('************')\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.fillna(' ')\n",
    "train=train.fillna(' ')\n",
    "test['total']= test['title']+' ' + test['text']\n",
    "train['total']=train['title']+' '+train['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Wordcloud Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuations from the String  \n",
    "s = \"!</> hello please$$ </>^s!!!u%%bs&&%$cri@@@be^^^&&!& </>*to@# the&&\\ cha@@@n##%^^&nel!@# %%$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = re.sub(r'[^\\w\\s]','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if any substring doesn't hold words or space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hello please subscribe to the channel \n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading nltk data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.append('helo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Covid-19 pandemic has impacted many countries and what it did to economy is very stressful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(sentence)\n",
    "words = [w for w in words if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid-19',\n",
       " 'pandemic',\n",
       " 'impacted',\n",
       " 'many',\n",
       " 'countries',\n",
       " 'economy',\n",
       " 'stressful']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "input_str=\"been had done languages cities mice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been\n",
      "had\n",
      "done\n",
      "language\n",
      "city\n",
      "mouse\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the sentence\n",
    "input_str=nltk.word_tokenize(input_str)\n",
    "\n",
    "#Lemmatize each word\n",
    "for word in input_str:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer=WordNetLemmatizer()\n",
    "#for index,row in train.iterrows():\n",
    "    #filter_sentence = ''\n",
    "    \n",
    "    #sentence = row['total']\n",
    "    #sentence = re.sub(r'[^\\w\\s]','',sentence) #cleaning\n",
    "    \n",
    "    #words = nltk.word_tokenize(sentence) #tokenization\n",
    "    \n",
    "    #words = [w for w in words if not w in stop_words]  #stopwords removal\n",
    "    \n",
    "    #for word in words:\n",
    "        #filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(word)).lower()\n",
    "        \n",
    "    #train.loc[index,'total'] = filter_sentence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying NLP Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['total']\n",
    "Y_train = train['label']\n",
    "Y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words / CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-iDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(features, max_features):\n",
    "    vectorizer = TfidfVectorizer( stop_words='english',\n",
    "                            decode_error='strict',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1, 2),\n",
    "                            max_features=max_features\n",
    "                            #max_df=0.5 # Verwendet im ML-Kurs unter Preprocessing                   \n",
    "                            )\n",
    "    feature_vec = vectorizer.fit_transform(features)\n",
    "    return feature_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = vectorize_text(['hello how are you doing','hi i am doing fine'],30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'hello how  doing','hi  doing fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44943642, 0.        , 0.        , 0.6316672 , 0.6316672 ,\n",
       "        0.        , 0.        ],\n",
       "       [0.33517574, 0.47107781, 0.47107781, 0.        , 0.        ,\n",
       "        0.47107781, 0.47107781]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature extraction using count vectorization and tfidf.\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(X_train)\n",
    "freq_term_matrix = count_vectorizer.transform(X_train)\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 104161)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in iter.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counts = count_vectorizer.transform(test['total'].values)\n",
    "test_tfidf = tfidf.transform(test_counts)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14897, 104161)\n"
     ]
    }
   ],
   "source": [
    "print(test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic classifier on training set: 1.00\n",
      "Accuracy of Logistic classifier on test set: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7733,   35],\n",
       "       [  40, 7089]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e7, max_iter = 1000)\n",
    "logreg.fit(tf_idf_matrix, Y_train)\n",
    "pred = logreg.predict(test_tfidf)\n",
    "print('Accuracy of Logistic classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(tf_idf_matrix, Y_train)))\n",
    "print('Accuracy of Logistic classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(test_tfidf, Y_test)))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic classifier on training set: 1.00\n",
      "Accuracy of Logistic classifier on test set: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7733,   35],\n",
       "       [  40, 7089]], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = logreg.predict(test_tfidf)\n",
    "print('Accuracy of Logistic classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(tf_idf_matrix, Y_train)))\n",
    "print('Accuracy of Logistic classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(test_tfidf, Y_test)))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB  classifier on training set: 0.95\n",
      "Accuracy of NB classifier on test set: 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7406,  362],\n",
       "       [ 565, 6564]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(tf_idf_matrix, Y_train)\n",
    "pred = NB.predict(test_tfidf)\n",
    "print('Accuracy of NB  classifier on training set: {:.2f}'\n",
    "     .format(NB.score(tf_idf_matrix, Y_train)))\n",
    "print('Accuracy of NB classifier on test set: {:.2f}'\n",
    "     .format(NB.score(test_tfidf, Y_test)))\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAC Accuracy: 99.4%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7719,   49],\n",
       "       [  40, 7089]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.75)\n",
    "vec_train=tfidf_vectorizer.fit_transform(X_train.values.astype('U')) \n",
    "vec_test=tfidf_vectorizer.transform(test['total'].values.astype('U'))\n",
    "\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(vec_train,Y_train)\n",
    "y_pred=pac.predict(vec_test)\n",
    "score=accuracy_score(Y_test,y_pred)\n",
    "print(f'PAC Accuracy: {round(score*100,2)}%')\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 98.83%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake_test = pd.read_csv('../fake-news/Fake.csv')\n",
    "real_test = pd.read_csv('../fake-news/True.csv')\n",
    "fake_label = [0 for i in range(fake_test.shape[0])]\n",
    "real_label = [1 for i in range(real_test.shape[0])]\n",
    "fake_test = fake_test.assign(label = fake_label)\n",
    "real_test = real_test.assign(label = real_label)\n",
    "\n",
    "x1 = pd.concat([fake_test,real_test])\n",
    "x1['total'] = x1['title'] + \" \" + x1['text']\n",
    "\n",
    "X=tfidf_vectorizer.transform(x1['total'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, x1['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 99.21%\n"
     ]
    }
   ],
   "source": [
    "X = count_vectorizer.transform(x1['total'].values)\n",
    "scores = cross_val_score(logreg, X, x1['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 92.57%\n"
     ]
    }
   ],
   "source": [
    "X = count_vectorizer.transform(x1['total'].values)\n",
    "scores = cross_val_score(NB, X, x1['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      30000\n",
       "text       30000\n",
       "subject    30000\n",
       "date       30000\n",
       "label      30000\n",
       "total      30000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold Accuracy: 96.7%\n",
      "K Fold Accuracy: 96.61%\n",
      "K Fold Accuracy: 90.84%\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../fake-news/train.csv')\n",
    "train = train.dropna()\n",
    "test = pd.read_csv('../fake-news/test.csv')\n",
    "train['total'] = train['title'] + \" \" + train['text']\n",
    "\n",
    "X=tfidf_vectorizer.transform(train['total'].values.astype('U'))\n",
    "scores = cross_val_score(pac, X, train['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')\n",
    "\n",
    "X = count_vectorizer.transform(train['total'].values)\n",
    "scores = cross_val_score(logreg, X, train['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')\n",
    "\n",
    "X = count_vectorizer.transform(train['total'].values)\n",
    "scores = cross_val_score(NB, X, train['label'].values, cv=5)\n",
    "print(f'K Fold Accuracy: {round(scores.mean()*100,2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X= count_vectorizer.transform([\"They hope to raise money to elect dozens of Democrats ahead of next week’s presidential and congressional elections. Cher announced on Twitter: “THURSDAY. Join me and [Hillary Clinton] to SIP TEA AND ELECT DEMOCRATS” Breitbart reports: Tickets for the event start at just $10 and go all the way up to $5,000 for a premium ticket that includes a “pre-event reception with Hillary & Cher.” “Chip in $10 or more to join our virtual conversation with Hillary Clinton & Cher on Thursday, October 29 at 4:30 PM ET,” the event’s description read. “Don’t miss this un-BELIEVE-able opportunity to hear from these two icons! Anything you donate will help elect over 50 House candidates and other Democrats on Election Day.” The event comes just days before next week’s presidential election in which both women are desperately fighting for a victory for Joe Biden over Donald Trump.As part of her 73rd birthday celebrations on Monday, Clinton pleaded with supporters to make a final push to remove Trump from office, four years after her devastating defeat in the 2016 presidential election.\"])\n",
    "X1 = count_vectorizer.transform([\"it’s the second-high nmber of daiy confirmed infecons since the beginning of the pandemic, behind the 3,004 reported on Sunday. The new cases account for just over three per cent of the 92,328 tests completed over the past day, according to provincial health data. Canada has now seen a total of 228,301 confirmed cases of COVID-19 to date, of which 191,208 have recovered from the disease. Over 11.5 million tests have been completed. Forty-two new deaths were also reported Thursday, bringing the national death toll to 10,074. Over a third of those deaths were historical and did not occur over the past 24 hours.\"])\n",
    "#y_pred=pac.predict(X1)\n",
    "#print(y_pred)\n",
    "pred2 = logreg.predict(X1)\n",
    "print(pred1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
